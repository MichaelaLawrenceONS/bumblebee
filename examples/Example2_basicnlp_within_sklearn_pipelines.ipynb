{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ```basicnlp``` functions to customise vectorizers within ```sklearn``` pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As José Blanco explained in his blogpost (https://towardsdatascience.com/hacking-scikit-learns-vectorizers-9ef26a7170af), one way to create a customised vectorizer is to instantiate the vectorizer using a modified version of Sklearn’s default analyzer.\n",
    "\n",
    "Under the hood, Sklearn’s vectorizers call a series of functions to convert a set of documents into a document-term matrix: \n",
    "- **```build_preprocessor```**: Returns a callable utilized to preprocess the input text before tokenization.\n",
    "- **```build_tokenizer:```** Creates a function capable of splitting a document’s corpus into tokens.\n",
    "- **```build_analyzer```**: Builds an analyzer function which applies preprocessing, tokenization, remove stop words and creates n-grams.\n",
    "\n",
    "By providing our own custom pipelines to either or all of these steps, we can customise the way we transform the text documents for analysis. \n",
    "\n",
    "And this is exactly what we'll do in this script:\n",
    "1. First, we customise the text pre-processing by only keeping those sentences in each text that are evaluated as subjective by ```TextBlob``` subjectivity algorithm.\n",
    "2. Second, we customise the text tokenisation by marking negations, removing punctuation and digits, and lemmatising the words.\n",
    "3. Finally, we train a SVM model to classify the polarity of each text using nested cross-validation which allows us to validate the model fitting procedure including the hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set ups and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and our user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nlpfunctions.utils import *\n",
    "from nlpfunctions.basicnlp import *\n",
    "from nlpfunctions.nlppipelineutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For the purpose of this notebook, we will import the labelled text data used in 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015 (available here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(os.getcwd())\n",
    "#print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb = pd.read_excel('Data/imdb.xlsx', header=0)\n",
    "yelp = pd.read_excel('Data/yelp_labelled.xlsx', header=0)\n",
    "\n",
    "imdb['source'] = 'imdb'\n",
    "yelp['source'] = 'yelp'\n",
    "\n",
    "df = pd.concat([imdb, yelp])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look a the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'score', 'source'], dtype='object')\n",
      "                                                text  score source\n",
      "0  A very, very, very slow-moving, aimless movie ...      0   imdb\n",
      "1  Not sure who was more lost - the flat characte...      0   imdb\n",
      "2  Attempting artiness with black & white and cle...      0   imdb\n",
      "3       Very little music or anything to speak of.        0   imdb\n",
      "4  The best scene in the movie was when Gerardo i...      1   imdb\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                 1742\n",
      "unique                1736\n",
      "top       I won't be back.\n",
      "freq                     2\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>imdb</th>\n",
       "      <td>361</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yelp</th>\n",
       "      <td>499</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "score     0    1\n",
       "source          \n",
       "imdb    361  384\n",
       "yelp    499  500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['text'].describe())   #there are some duplicates\n",
    "\n",
    "pd.crosstab(df['source'], df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.duplicated('text')]\n",
    "df = df.drop_duplicates('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[pd.isnull(df['text'])]   #yep, 1 case\n",
    "df = df[pd.notnull(df['text'])]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customise text pre-processing within ```sklearn``` pipelines in ```CountVectorizer()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build an ad-hoc pre-processing pipeline\n",
    "\n",
    "For our customised pre-processing step (i.e., before tokenisation), let's remove all sentences within each text that score too low on subjectivity. We'll pick 0.3 as our subjectivity threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?remove_objective_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_preprocessor = combine_functions(sent_tokenise\n",
    "                                    , lambda x : remove_objective_sents(x, 0.3)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build ad-hoc word-tokenisation pipeline\n",
    "\n",
    "Let's then lemmatise, mark negations, remove numeric digits and punctuation as part of our customised tokenisation pipeline. \n",
    "Lemmatisaion requires that we first POS-tag the text.\n",
    "\n",
    "Importantly, the output of our pipeline must be a list of token lists as this is the required output for the next step in the vecorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tokenizer_pipe = combine_functions(word_tokenise\n",
    "                                       ,to_lower\n",
    "                                       ,POS_tagging\n",
    "                                       ,lemmatise\n",
    "                                       ,fix_neg_auxiliary\n",
    "                                       ,lambda x : remove_stopwords(x, extra_stopwords = [\n",
    "                                           'x', \"'s\", 'us', 'ca', 'many', 'much', 'one', 'put', '¬ñ',\n",
    "                                           'also', 'get', 'would', 'could', 'like', 'go', 'lot', 'make'\n",
    "                                       ])\n",
    "                                       ,lambda s: [[re.sub(r'\\d+','',x) for x in subs] for subs in s]\n",
    "                                       ,mark_neg\n",
    "                                       ,flattenIrregularListOfLists  # now we have one list of tokens per text\n",
    "                                       ,lambda x: list(filter(None, x))   # end with a list of token lists, each sublist is a text\n",
    "                                       )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In case you are wondering\n",
    "\n",
    "?fix_neg_auxiliary\n",
    "?mark_neg\n",
    "?flattenIrregularListOfLists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build ad-hoc ```CountVectorizer()```\n",
    "\n",
    "We can now use our ad-hoc preprocessor and tokenizer within ```CountVectorizer```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_vec = CountVectorizer(preprocessor = my_preprocessor,\n",
    "                         tokenizer = my_tokenizer_pipe,\n",
    "                         analyzer=\"word\",\n",
    "                         ngram_range = (1,3),\n",
    "                         stop_words=None\n",
    "                         #min_df=1\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Instantiate our custom BoW pipeline\n",
    "\n",
    "We will use the ```Transformers``` ```ColumnSelector()``` and ```Series2ListOfStrings()``` to select the ```pandas.Series``` that contains the text data and transform it into a list of strings which is ```CountVecorizer()```'s required input format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_bags_words = Pipeline([\n",
    "        \n",
    "        ('selector', ColumnSelector(columns=['text'])),\n",
    "        \n",
    "        ('transformer', Series2ListOfStrings()),\n",
    "        \n",
    "        ('vec', my_vec)\n",
    "        \n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's apply our custom BoW pipeline to our data\n",
    "\n",
    "Let's take a look at the most frequent words first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>the</td>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "      <td>I</td>\n",
       "      <td>is</td>\n",
       "      <td>of</td>\n",
       "      <td>was</td>\n",
       "      <td>to</td>\n",
       "      <td>The</td>\n",
       "      <td>this</td>\n",
       "      <td>...</td>\n",
       "      <td>one</td>\n",
       "      <td>an</td>\n",
       "      <td>great</td>\n",
       "      <td>really</td>\n",
       "      <td>all</td>\n",
       "      <td>about</td>\n",
       "      <td>by</td>\n",
       "      <td>they</td>\n",
       "      <td>time</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1012</td>\n",
       "      <td>779</td>\n",
       "      <td>618</td>\n",
       "      <td>534</td>\n",
       "      <td>473</td>\n",
       "      <td>468</td>\n",
       "      <td>461</td>\n",
       "      <td>441</td>\n",
       "      <td>354</td>\n",
       "      <td>287</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>68</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8     9   ...    40  41  \\\n",
       "word    the  and    a    I   is   of  was   to  The  this  ...   one  an   \n",
       "count  1012  779  618  534  473  468  461  441  354   287  ...    74  71   \n",
       "\n",
       "          42      43   44     45  46    47    48    49  \n",
       "word   great  really  all  about  by  they  time  from  \n",
       "count     69      68   66     62  61    59    59    59  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial\n",
    "\n",
    "all_words = df['text'].str.split(expand=True).unstack().value_counts()\n",
    "all_words = all_words.to_frame().reset_index().rename(columns = {'index' : 'word', 0 : 'count'})\n",
    "\n",
    "# get 50 more frequent words, lots of \"rubbish\"\n",
    "#all_words[:50].plot.bar(x='word')\n",
    "all_words[:50].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0    A very, very, very slow-moving, aimless movie ...\n",
      "1    Not sure who was more lost - the flat characte...\n",
      "2    Attempting artiness with black & white and cle...\n",
      "3         Very little music or anything to speak of.  \n",
      "4    The best scene in the movie was when Gerardo i...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(df['text']))\n",
    "print(df['text'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average best</th>\n",
       "      <th>avoid</th>\n",
       "      <th>award</th>\n",
       "      <th>away</th>\n",
       "      <th>awesome</th>\n",
       "      <th>awesome service</th>\n",
       "      <th>awful</th>\n",
       "      <th>baby</th>\n",
       "      <th>back</th>\n",
       "      <th>backNEG</th>\n",
       "      <th>backNEG NEG</th>\n",
       "      <th>bacon</th>\n",
       "      <th>bad</th>\n",
       "      <th>bad acting</th>\n",
       "      <th>bad bad</th>\n",
       "      <th>bad even</th>\n",
       "      <th>bad experience</th>\n",
       "      <th>bad film</th>\n",
       "      <th>bad film ever</th>\n",
       "      <th>bad food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average best  avoid  award  away  awesome  awesome service  awful  baby  \\\n",
       "1             0      0      0     0        0                0      0     0   \n",
       "2             0      0      0     0        0                0      0     0   \n",
       "3             0      0      0     0        0                0      0     0   \n",
       "4             0      0      0     0        0                0      0     0   \n",
       "5             0      0      0     0        0                0      0     0   \n",
       "\n",
       "   back  backNEG  backNEG NEG  bacon  bad  bad acting  bad bad  bad even  \\\n",
       "1     0        0            0      0    0           0        0         0   \n",
       "2     0        0            0      0    0           0        0         0   \n",
       "3     0        0            0      0    0           0        0         0   \n",
       "4     0        0            0      0    0           0        0         0   \n",
       "5     0        0            0      0    0           0        0         0   \n",
       "\n",
       "   bad experience  bad film  bad film ever  bad food  \n",
       "1               0         0              0         0  \n",
       "2               0         0              0         0  \n",
       "3               0         0              0         0  \n",
       "4               0         0              0         0  \n",
       "5               0         0              0         0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at a random part of the output of our customised Vectoriser\n",
    "pd.DataFrame(pipe_bags_words.fit_transform(df).A, columns=my_vec.get_feature_names()).iloc[1:6, 100:120]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the customised Vectorizer to some new random data, using the vocabulary just learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average best</th>\n",
       "      <th>avoid</th>\n",
       "      <th>award</th>\n",
       "      <th>away</th>\n",
       "      <th>awesome</th>\n",
       "      <th>awesome service</th>\n",
       "      <th>awful</th>\n",
       "      <th>baby</th>\n",
       "      <th>back</th>\n",
       "      <th>backNEG</th>\n",
       "      <th>backNEG NEG</th>\n",
       "      <th>bacon</th>\n",
       "      <th>bad</th>\n",
       "      <th>bad acting</th>\n",
       "      <th>bad bad</th>\n",
       "      <th>bad even</th>\n",
       "      <th>bad experience</th>\n",
       "      <th>bad film</th>\n",
       "      <th>bad film ever</th>\n",
       "      <th>bad food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average best  avoid  award  away  awesome  awesome service  awful  baby  \\\n",
       "0             0      0      0     0        0                0      0     0   \n",
       "\n",
       "   back  backNEG  backNEG NEG  bacon  bad  bad acting  bad bad  bad even  \\\n",
       "0     0        0            0      0    0           0        0         0   \n",
       "\n",
       "   bad experience  bad film  bad film ever  bad food  \n",
       "0               0         0              0         0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = pd.DataFrame([\"Would you tell me, please, which way I ought to go from here? That depends a good deal on where you want to get to. I don’t much care where! Then it doesn’t matter which way you go.\"], columns=['text'])\n",
    "\n",
    "pd.DataFrame(pipe_bags_words.transform(new_text).A, columns=my_vec.get_feature_names()).iloc[:, 100:120]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train an SVM classifier on the combined BoW features we have just computed with our customised vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bags_words = Pipeline([\n",
    "        \n",
    "        ('selector', ColumnSelector(columns=['text'])),\n",
    "        \n",
    "        ('transformer', Series2ListOfStrings()),\n",
    "        \n",
    "        ('vec', my_vec),\n",
    "    \n",
    "        ('tf_idf', TfidfTransformer())\n",
    "        \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate pipeline\n",
    "\n",
    "pipe_bow_svm = Pipeline([\n",
    "        \n",
    "        ('bow', pipe_bags_words),\n",
    "        \n",
    "        ('classifier', svm)\n",
    "        \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check list of available hyperparameters\n",
    "\n",
    "pipe_bow_svm_cv.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define parameters space and dictionary\n",
    "\n",
    "parameters = dict(\n",
    "        \n",
    "        #bow__vec__max_features = np.arange(5000, 11000, step=1000),\n",
    "    \n",
    "        classifier__kernel = ['linear', 'rbf'],\n",
    "        \n",
    "        classifier__C = [0.01, 0.1, 1, 10, 100]\n",
    "        \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch and nested cross-validation \n",
    "\n",
    "Nested cross-validation (CV) is often used to train a model in which hyperparameters also need to be optimized. Nested CV estimates the generalization error of the underlying model and its (hyper)parameter search. \n",
    "\n",
    "More on this here:\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
    "\n",
    "And check these excellent explanations https://stats.stackexchange.com/a/65156 and https://chrisalbon.com/machine_learning/model_evaluation/nested_cross_validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a development dataset and an holdout dataset\n",
    "df_dev, df_holdout = train_test_split(df, test_size=0.20, stratify=df.score, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = df_dev[['text']]\n",
    "y_dev = df_dev.score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for nested cross-validation\n",
    "\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=77)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=77)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate non_nested parameter search via GridSearch on the inner cv loop\n",
    "pipe_bow_svm_cv = GridSearchCV(estimator=pipe_bow_svm,\n",
    "                              param_grid=parameters,\n",
    "                              cv=inner_cv,\n",
    "                              return_train_score=True,\n",
    "                              scoring='accuracy'    #could be smth else, e.g., \"neg_log_loss\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe_bow_svm_cv.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nested CV with parameter optimization to estimate the generalization error (this might take a while...) \n",
    "# Note: The outer cross validation estimates generalization error for a training function that includes tuning. \n",
    "\n",
    "# pipe_bow_svm_cv's GridSearchCV runs the inner loop while cross_val_score() runs the outer loop\n",
    "nested_score = cross_val_score(pipe_bow_svm_cv, X=X_dev, y=y_dev, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77697842,  0.78417266,  0.75179856,  0.76895307,  0.75451264])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_score\n",
    "\n",
    "# model fitting approach seems to give stable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the peformance on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_hout = df_holdout[['text']]\n",
    "y_hout = df_holdout.score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=77, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('bow', Pipeline(memory=None,\n",
       "     steps=[('selector', ColumnSelector(columns=['text'])), ('transformer', Series2ListOfStrings()), ('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowe...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'classifier__kernel': ['linear', 'rbf'], 'classifier__C': [0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier procedure on the whole development set\n",
    "# Our final model (trained on the whole data set) is basically the inner CV loop applied to the whole development data set.\n",
    "\n",
    "pipe_bow_svm_cv.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', Pipeline(memory=None,\n",
       "     steps=[('selector', ColumnSelector(columns=['text'])), ('transformer', Series2ListOfStrings()), ('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowe...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at the best model\n",
    "pipe_bow_svm_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned pipeline's Hyperparameters: {'classifier__C': 1, 'classifier__kernel': 'linear'}\n",
      "Accuracy or best score: 0.7672910662824207\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned pipeline's Hyperparameters: {}\".format(pipe_bow_svm_cv.best_params_))\n",
    "print(\"Accuracy or best score: {}\".format(pipe_bow_svm_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': 0.01, 'classifier__kernel': 'linear'} test score: 0.532 vs. train score: 0.544\n",
      "{'classifier__C': 0.01, 'classifier__kernel': 'rbf'} test score: 0.532 vs. train score: 0.544\n",
      "{'classifier__C': 0.1, 'classifier__kernel': 'linear'} test score: 0.55 vs. train score: 0.553\n",
      "{'classifier__C': 0.1, 'classifier__kernel': 'rbf'} test score: 0.532 vs. train score: 0.544\n",
      "{'classifier__C': 1, 'classifier__kernel': 'linear'} test score: 0.767 vs. train score: 0.888\n",
      "{'classifier__C': 1, 'classifier__kernel': 'rbf'} test score: 0.532 vs. train score: 0.544\n",
      "{'classifier__C': 10, 'classifier__kernel': 'linear'} test score: 0.741 vs. train score: 0.888\n",
      "{'classifier__C': 10, 'classifier__kernel': 'rbf'} test score: 0.532 vs. train score: 0.544\n",
      "{'classifier__C': 100, 'classifier__kernel': 'linear'} test score: 0.741 vs. train score: 0.888\n",
      "{'classifier__C': 100, 'classifier__kernel': 'rbf'} test score: 0.532 vs. train score: 0.544\n"
     ]
    }
   ],
   "source": [
    "# Inspect results for each combination of parameters' value\n",
    "cv_results = pipe_bow_svm_cv.cv_results_\n",
    "#print(cv_results.keys())\n",
    "\n",
    "for mean_test_score, mean_train_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"mean_train_score\"], cv_results[\"params\"]):\n",
    "    #print(type(mean_test_score))\n",
    "    print(params, 'test score: %s ' %round(mean_test_score, 3) + 'vs. train score: %s' %round(mean_train_score, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781609195402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.86      0.79       171\n",
      "          1       0.84      0.71      0.77       177\n",
      "\n",
      "avg / total       0.79      0.78      0.78       348\n",
      "\n",
      "[[147  24]\n",
      " [ 52 125]]\n"
     ]
    }
   ],
   "source": [
    "print(pipe_bow_svm_cv.score(X_hout, y_hout))    #testing accuracy\n",
    "\n",
    "y_predictions = pipe_bow_svm_cv.predict(X_hout)\n",
    "\n",
    "print(classification_report(y_true = y_hout, y_pred = y_predictions ))\n",
    "\n",
    "# [true-negative, false-positive, false-negative, true-positive] \n",
    "print(confusion_matrix(y_true = y_hout, y_pred = y_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
